import Foundation

//
// ContentValidator.swift
// SignalAir
//
// å…§å®¹é©—è­‰å’Œåˆ†é¡ç³»çµ±
//

/// ä¸ç•¶å…§å®¹é¡å‹å®šç¾©
enum InappropriateContentType: String, CaseIterable {
    case phishing = "phishing"
    case botGenerated = "bot_generated"
    
    var severity: ContentValidationSeverity {
        switch self {
        case .phishing:
            return .high
        case .botGenerated:
            return .critical
        }
    }
    
    var description: String {
        switch self {
        case .phishing:
            return "ç¶²è·¯é‡£é­š"
        case .botGenerated:
            return "æ©Ÿå™¨äººå…§å®¹"
        }
    }
}

/// å…§å®¹é©—è­‰åš´é‡æ€§ç­‰ç´š
enum ContentValidationSeverity: Int, CaseIterable, Comparable {
    case low = 1
    case medium = 2
    case high = 3
    case critical = 4
    
    var trustScorePenalty: Double {
        switch self {
        case .low: return 5.0
        case .medium: return 10.0
        case .high: return 15.0
        case .critical: return 30.0
        }
    }
    
    static func < (lhs: ContentValidationSeverity, rhs: ContentValidationSeverity) -> Bool {
        return lhs.rawValue < rhs.rawValue
    }
}

/// å…§å®¹åˆ†æçµæœ
struct ContentAnalysisResult {
    let isClean: Bool
    let detectedTypes: [InappropriateContentType]
    let confidence: Double // 0.0 - 1.0
    let details: String
    
    var maxSeverity: ContentValidationSeverity {
        return detectedTypes.map { $0.severity }.max() ?? .low
    }
}

/// å…§å®¹é©—è­‰å™¨
class ContentValidator {
    
    // MARK: - ä¸ç•¶å…§å®¹é—œéµè©åº«
    
    private let phishingKeywords = [
        // ä¸­æ–‡é‡£é­šè©å½™
        "é»æ“Šé€£çµ", "è¼¸å…¥å¯†ç¢¼", "ç·Šæ€¥é©—è­‰", "å¸³è™Ÿç•°å¸¸", "ç«‹å³è™•ç†", "å¸³æˆ¶å‡çµ",
        "å®‰å…¨é©—è­‰", "èº«ä»½ç¢ºèª", "æ›´æ–°è³‡æ–™", "é‡è¨­å¯†ç¢¼", "é©—è­‰ç¢¼", "ç™»å…¥ç¢ºèª",
        
        // è‹±æ–‡é‡£é­šè©å½™
        "click here", "verify account", "urgent", "suspended", "login",
        "update payment", "confirm identity", "security alert", "expired"
    ]
    
    // MARK: - ä¸»è¦æª¢æ¸¬æ–¹æ³•
    
    /// åˆ†ææ–‡å­—å…§å®¹æ˜¯å¦åŒ…å«ä¸ç•¶å…§å®¹
    func analyzeContent(_ text: String) -> ContentAnalysisResult {
        let cleanText = text.lowercased().trimmingCharacters(in: .whitespacesAndNewlines)
        var detectedTypes: [InappropriateContentType] = []
        var confidence: Double = 0.0
        
        // æª¢æ¸¬ç¶²è·¯é‡£é­šï¼ˆåŒ…å«URLæª¢æ¸¬ï¼‰
        if containsKeywords(cleanText, from: phishingKeywords) || containsURL(cleanText) {
            detectedTypes.append(.phishing)
            confidence = max(confidence, 0.9)
        }
        
        // æª¢æ¸¬æ©Ÿå™¨äººç”Ÿæˆå…§å®¹ï¼ˆåŸºæ–¼æ¨¡å¼ï¼‰
        if detectBotPattern(cleanText) {
            detectedTypes.append(.botGenerated)
            confidence = max(confidence, 0.95)
        }
        
        let details = detectedTypes.isEmpty ? "å…§å®¹æ¸…æ½”" : "æª¢æ¸¬åˆ°: \(detectedTypes.map { $0.description }.joined(separator: ", "))"
        
        return ContentAnalysisResult(
            isClean: detectedTypes.isEmpty,
            detectedTypes: detectedTypes,
            confidence: confidence,
            details: details
        )
    }
    
    // MARK: - è¼”åŠ©æª¢æ¸¬æ–¹æ³•
    
    private func containsKeywords(_ text: String, from keywords: [String]) -> Bool {
        return keywords.contains { keyword in
            text.contains(keyword)
        }
    }
    
    private func containsURL(_ text: String) -> Bool {
        // æª¢æ¸¬å¸¸è¦‹URLæ¨¡å¼
        let urlPatterns = [
            "http://", "https://", "www.", ".com", ".net", ".org", ".tw", ".cn"
        ]
        
        return urlPatterns.contains { pattern in
            text.contains(pattern)
        }
    }
    
    private func detectBotPattern(_ text: String) -> Bool {
        // æª¢æ¸¬æ©Ÿå™¨äººæ¨¡å¼ï¼š
        // 1. éåº¦é‡è¤‡çš„å­—ç¬¦
        let repeatingPattern = try? NSRegularExpression(pattern: "(.{1,3})\\1{4,}", options: [])
        if let regex = repeatingPattern,
           regex.firstMatch(in: text, range: NSRange(text.startIndex..., in: text)) != nil {
            return true
        }
        
        // 2. ç•°å¸¸çš„å¤§å¯«æ¨¡å¼
        let uppercaseRatio = Double(text.filter { $0.isUppercase }.count) / Double(text.count)
        if uppercaseRatio > 0.8 && text.count > 10 {
            return true
        }
        
        // 3. éå¤šçš„ç‰¹æ®Šå­—ç¬¦
        let specialCharRatio = Double(text.filter { !$0.isLetter && !$0.isNumber && !$0.isWhitespace }.count) / Double(text.count)
        if specialCharRatio > 0.5 && text.count > 5 {
            return true
        }
        
        return false
    }
    
    /// å¿«é€Ÿæª¢æŸ¥æ˜¯å¦ç‚ºæ˜é¡¯ä¸ç•¶å…§å®¹
    func isObviouslyInappropriate(_ text: String) -> Bool {
        let result = analyzeContent(text)
        return !result.isClean && result.confidence > 0.8
    }
    
    /// å–å¾—å»ºè­°çš„è™•ç†å‹•ä½œ
    func getRecommendedAction(for result: ContentAnalysisResult) -> ContentModerationAction {
        if result.isClean {
            return .allow
        }
        
        switch result.maxSeverity {
        case .low:
            return .warn
        case .medium:
            return .filter
        case .high:
            return .block
        case .critical:
            return .blockAndRestrict
        }
    }
}

/// å…§å®¹å¯©æ ¸å‹•ä½œ
enum ContentModerationAction {
    case allow          // å…è¨±
    case warn           // è­¦å‘Š
    case filter         // éæ¿¾
    case block          // é˜»æ“‹
    case blockAndRestrict    // é˜»æ“‹ä¸¦é™åˆ¶
}

/// æ“´å±•ï¼šèˆ‡ç¾æœ‰ä¿¡ä»»åˆ†æ•¸ç³»çµ±æ•´åˆ
extension ContentValidator {
    
    /// æª¢æ¸¬ä¸ç•¶å…§å®¹ä¸¦å›å ±çµ¦ä¿¡ä»»åˆ†æ•¸ç³»çµ±
    func validateAndReport(_ text: String, from deviceUUID: String, trustManager: TrustScoreManager) -> Bool {
        let result = analyzeContent(text)
        
        if !result.isClean {
            // è§¸ç™¼ä¿¡ä»»åˆ†æ•¸æ‡²ç½°
            trustManager.recordSuspiciousBehavior(for: deviceUUID, behavior: .inappropriateContent)
            
            // è¨˜éŒ„å®‰å…¨äº‹ä»¶
            let _ = SecurityEvent(
                peerID: deviceUUID,
                type: .suspiciousActivity,
                severity: mapToSecuritySeverity(result.maxSeverity),
                details: "ä¸ç•¶å…§å®¹æª¢æ¸¬: \(result.details)",
                sourceComponent: "ContentValidator"
            )
            
            print("ğŸš¨ æª¢æ¸¬åˆ°ä¸ç•¶å…§å®¹: \(result.details) ä¾†è‡ª: \(deviceUUID)")
            return false
        }
        
        return true
    }
    
    private func mapToSecuritySeverity(_ contentSeverity: ContentValidationSeverity) -> SecuritySeverity {
        switch contentSeverity {
        case .low: return .low
        case .medium: return .medium
        case .high: return .high
        case .critical: return .critical
        }
    }
}